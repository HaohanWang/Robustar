{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Robustar Interactive Toolbox for Precise Data Annotation and Robust Vision Learning, which aims to improve the robustness of vision classification machine learning models through a data-driven perspective. Building upon the recent understanding that the lack of machine learning model's robustness is the tendency of the model's learning of spurious features, we aim to solve this problem from its root at the data perspective by removing the spurious features from the data before training. In particular, we introduce a software that helps the users to better prepare the data for training image classification models by allowing the users to annotate the spurious features at the pixel level of images. To facilitate this process, our software also leverages recent advances to help identify potential images and pixels worthy of attention and to continue the training with newly annotated data.","title":"Home"},{"location":"#welcome-to-robustar","text":"Interactive Toolbox for Precise Data Annotation and Robust Vision Learning, which aims to improve the robustness of vision classification machine learning models through a data-driven perspective. Building upon the recent understanding that the lack of machine learning model's robustness is the tendency of the model's learning of spurious features, we aim to solve this problem from its root at the data perspective by removing the spurious features from the data before training. In particular, we introduce a software that helps the users to better prepare the data for training image classification models by allowing the users to annotate the spurious features at the pixel level of images. To facilitate this process, our software also leverages recent advances to help identify potential images and pixels worthy of attention and to continue the training with newly annotated data.","title":"Welcome to Robustar"},{"location":"get_started/","text":"Setup In progress...","title":"Get Started"},{"location":"get_started/#setup","text":"In progress...","title":"Setup"},{"location":"developer/developer_guide/","text":"Developer Guide We will go through the implementation details for Robustar. For environment setup issues, please follow the frontend setup guide , backend setup guide and launcher setup guide in our repository. Robustar Architecture Robustar's architecture is shown below. Robustar is developed as a Web application wrapped in a docker image. We use Web stack mainly because of the following reasons: With Web GUI, we don't need to worry about cross platform issues. There is more abundant resources for developing good visual components with Web. With a separate frontend and backend, it is easier to refactor Robustar if we want to deploy it on the cloud in a SaaS manner in the future. For now, users will need to pull the docker image and host the frontend and backend on their own machines. However, we hide the docker layer away with a launcher. They can simply download the launcher, click a few buttons on the GUI, and then use a browser to use Robustar. The launcher is implemented in Python with pyside2 (something similar to PyQT ). It can be compiled for multiple systems. We will talk about the launcher later. The Frontend Here is a list of the main stack we used for the frontend. Library / Tool Usage HTML/CSS, JavaScript, Vue.js Web basics & frontend framework Lerna Monorepo management Vuetify Visual component library eslint & prettier Code Styling Axios API client Cypress Unit tests & end-to-end tests Besides, we adopted tui-image-editor to suit our image annotation needs and placed it in our repository. Thus, we have two separate packages for the frontend: image-editor package for tui-image-editor and robustar for the main frontend. robustar package relies on image-editor , and this is managed by lerna . The main Robustar interface is in /front-end/packages/robustar/src . These are the most important folders: views/ : Each file corresponds to a page that can be accessed with a different URL. components/ : Stores visual components, for example, model visualizers, that can be used in multiple pages. services/ : Stores all API call utilities. For tui-image-editor , please visit their GitHub page . The Backend Here are the main backend libraries we used: Library / Tool Usage Flask API server in Python python-socketio Socket connection utility SQLite Database Flashtorch Model saliency map visualization pytorch_influence_functions Influence function calculation Pillow Python's image library PyTorch, torchvision, numpy, scipy Machine learning pipeline utilities Tensorboard Model training visualization pytest Unit test The backend is organized as follows: apis/ : All API endpoint definitions ml/ : All code related to the machine learning pipeline (e.g., dataset definition, influence calculation, trainer initialization, ...) modules/ : Independent modules (usually code adopted from other places) bg_remove/ : For auto-removing the background of images with a image segmentation model influence_module/ : For influence function calculations visualize_module : For saliency map visualization (with flashtorch ) objects/ : All important Python Classes RAutoAnnotator : A wrapper for image segmentation model for background removal RDataManager : Represents the entire dataset (all splits + paired data). A aggregation of RImageFolders . RImageFolder : Represents a data split. Supports data manipulation and interacts with the SQLite database. RModelWrapper : A wrapper for models that the user is training / interacting with. RServer : Represents the entire server instance. Stores useful global information. RTask : Represents a task (e.g., model training, batch auto-annotation, testing...), which usually takes some time to finish. Can be started / updated / stopped. utils/ : Implementation of APIs. tests/ : Test cases. Backend File System Interaction The backend will read from / write to the local storage inside the container. Specifically: It will initialize a SQLite database if it does not exist. All metadata will be stored in the database. These include: All data records All visualization records All influence records All correctly/incorrectly classified samples It will save model's checkpoint. It will save the images annotated by the user. It will save any pre-calculated results, such as visualization images and background removal proposals. When starting the container with a launcher, users can mount these files from their file system into the container, so that any changes will be reflected in their file system. Inside the container, the backend will access these files with hard coded paths, which are available in RServer object. CI/CD & Tests Backend tests are available in back-end/tests . Frontend tests are available in front-end/cypress/tests/components . Refer to frontend and backend setup guide in our repo to run these tests locally. We use CircleCI to perform CI/CD tasks. The configuration can be found in .circleci/config.yml . We do the following in the pipeline Pull code from GitHub Download dependencies and dev dataset Run all test cases Build docker image Push docker image to DockerHub If the commit is made to the main branch, we will trigger a release build, which has a tag of the format x.y.z . Otherwise, when the any commit is pushed to other branches, we trigger a dev build with tag x.y.<commit_hash> . Docker We build a docker image in two steps. First, we will build a base image with /docker-base/DOCKERFILE , which will include all necessary libraries and tools ready, except for everything related to PyTorch. Then, based on the base image, we then build the full image with /DOCKERFILE . Note that we can supply an argument specifying the CUDA version to build for, and the script /scripts/install_pytorch.sh will install the corresponding version. Launcher Here are the main launcher libraries and development tools we used: Library / Tool Usage PySide2 Python\u2019s QT library docker Python\u2019s Docker library Qt Designer GUI QT development tool PyUIC Tool that converts .ui files to .py files The launcher is developed adhering to Model\u2013View\u2013Controller(MVC) pattern and is organized as follows: app.py : Main file of the launcher. model/ : The launcher model. Each property is defined with the decoration of @property and its corresponding setter function is defined with @<property name>.setter . resources/ : All .ui files developed with Qt Designer . views/ : All view files in pairs. Specifically, xx_view_ui.py generated directly from a .ui file with PyUIC pairs with xx_view.py , which connects signals in the view to corresponding controller functions. controllers/ : All controller classes main_ctrl.py : Contains MainController class, including functions controlling the general behavior of the launcher. Two main types of functions shall be distinguished, functions beginning with setM and setV . The former ones are functions called by views to change the model, and the latter ones are functions called by the model to change the view. docker_ctrl.py : Contains DockerController class, including docker relevant operation functions. \u200b To package the launcher, please follow the launcher setup guide in our repository.","title":"System overview"},{"location":"developer/developer_guide/#developer-guide","text":"We will go through the implementation details for Robustar. For environment setup issues, please follow the frontend setup guide , backend setup guide and launcher setup guide in our repository.","title":"Developer Guide"},{"location":"developer/developer_guide/#robustar-architecture","text":"Robustar's architecture is shown below. Robustar is developed as a Web application wrapped in a docker image. We use Web stack mainly because of the following reasons: With Web GUI, we don't need to worry about cross platform issues. There is more abundant resources for developing good visual components with Web. With a separate frontend and backend, it is easier to refactor Robustar if we want to deploy it on the cloud in a SaaS manner in the future. For now, users will need to pull the docker image and host the frontend and backend on their own machines. However, we hide the docker layer away with a launcher. They can simply download the launcher, click a few buttons on the GUI, and then use a browser to use Robustar. The launcher is implemented in Python with pyside2 (something similar to PyQT ). It can be compiled for multiple systems. We will talk about the launcher later.","title":"Robustar Architecture"},{"location":"developer/developer_guide/#the-frontend","text":"Here is a list of the main stack we used for the frontend. Library / Tool Usage HTML/CSS, JavaScript, Vue.js Web basics & frontend framework Lerna Monorepo management Vuetify Visual component library eslint & prettier Code Styling Axios API client Cypress Unit tests & end-to-end tests Besides, we adopted tui-image-editor to suit our image annotation needs and placed it in our repository. Thus, we have two separate packages for the frontend: image-editor package for tui-image-editor and robustar for the main frontend. robustar package relies on image-editor , and this is managed by lerna . The main Robustar interface is in /front-end/packages/robustar/src . These are the most important folders: views/ : Each file corresponds to a page that can be accessed with a different URL. components/ : Stores visual components, for example, model visualizers, that can be used in multiple pages. services/ : Stores all API call utilities. For tui-image-editor , please visit their GitHub page .","title":"The Frontend"},{"location":"developer/developer_guide/#the-backend","text":"Here are the main backend libraries we used: Library / Tool Usage Flask API server in Python python-socketio Socket connection utility SQLite Database Flashtorch Model saliency map visualization pytorch_influence_functions Influence function calculation Pillow Python's image library PyTorch, torchvision, numpy, scipy Machine learning pipeline utilities Tensorboard Model training visualization pytest Unit test The backend is organized as follows: apis/ : All API endpoint definitions ml/ : All code related to the machine learning pipeline (e.g., dataset definition, influence calculation, trainer initialization, ...) modules/ : Independent modules (usually code adopted from other places) bg_remove/ : For auto-removing the background of images with a image segmentation model influence_module/ : For influence function calculations visualize_module : For saliency map visualization (with flashtorch ) objects/ : All important Python Classes RAutoAnnotator : A wrapper for image segmentation model for background removal RDataManager : Represents the entire dataset (all splits + paired data). A aggregation of RImageFolders . RImageFolder : Represents a data split. Supports data manipulation and interacts with the SQLite database. RModelWrapper : A wrapper for models that the user is training / interacting with. RServer : Represents the entire server instance. Stores useful global information. RTask : Represents a task (e.g., model training, batch auto-annotation, testing...), which usually takes some time to finish. Can be started / updated / stopped. utils/ : Implementation of APIs. tests/ : Test cases.","title":"The Backend"},{"location":"developer/developer_guide/#backend-file-system-interaction","text":"The backend will read from / write to the local storage inside the container. Specifically: It will initialize a SQLite database if it does not exist. All metadata will be stored in the database. These include: All data records All visualization records All influence records All correctly/incorrectly classified samples It will save model's checkpoint. It will save the images annotated by the user. It will save any pre-calculated results, such as visualization images and background removal proposals. When starting the container with a launcher, users can mount these files from their file system into the container, so that any changes will be reflected in their file system. Inside the container, the backend will access these files with hard coded paths, which are available in RServer object.","title":"Backend File System Interaction"},{"location":"developer/developer_guide/#cicd-tests","text":"Backend tests are available in back-end/tests . Frontend tests are available in front-end/cypress/tests/components . Refer to frontend and backend setup guide in our repo to run these tests locally. We use CircleCI to perform CI/CD tasks. The configuration can be found in .circleci/config.yml . We do the following in the pipeline Pull code from GitHub Download dependencies and dev dataset Run all test cases Build docker image Push docker image to DockerHub If the commit is made to the main branch, we will trigger a release build, which has a tag of the format x.y.z . Otherwise, when the any commit is pushed to other branches, we trigger a dev build with tag x.y.<commit_hash> .","title":"CI/CD &amp; Tests"},{"location":"developer/developer_guide/#docker","text":"We build a docker image in two steps. First, we will build a base image with /docker-base/DOCKERFILE , which will include all necessary libraries and tools ready, except for everything related to PyTorch. Then, based on the base image, we then build the full image with /DOCKERFILE . Note that we can supply an argument specifying the CUDA version to build for, and the script /scripts/install_pytorch.sh will install the corresponding version.","title":"Docker"},{"location":"developer/developer_guide/#launcher","text":"Here are the main launcher libraries and development tools we used: Library / Tool Usage PySide2 Python\u2019s QT library docker Python\u2019s Docker library Qt Designer GUI QT development tool PyUIC Tool that converts .ui files to .py files The launcher is developed adhering to Model\u2013View\u2013Controller(MVC) pattern and is organized as follows: app.py : Main file of the launcher. model/ : The launcher model. Each property is defined with the decoration of @property and its corresponding setter function is defined with @<property name>.setter . resources/ : All .ui files developed with Qt Designer . views/ : All view files in pairs. Specifically, xx_view_ui.py generated directly from a .ui file with PyUIC pairs with xx_view.py , which connects signals in the view to corresponding controller functions. controllers/ : All controller classes main_ctrl.py : Contains MainController class, including functions controlling the general behavior of the launcher. Two main types of functions shall be distinguished, functions beginning with setM and setV . The former ones are functions called by views to change the model, and the latter ones are functions called by the model to change the view. docker_ctrl.py : Contains DockerController class, including docker relevant operation functions. \u200b To package the launcher, please follow the launcher setup guide in our repository.","title":"Launcher"},{"location":"tutorial/launcher/launcher/","text":"Introduction Robustar Launcher is an interactive app that you can use to control docker containers of Robustar. You can either run the executable file provided here or the code of it to use it. Contents Overview of Robustar Launcher Start Robustar Launcher Use Robustar Launcher Create new docker container Check existing docker containers Manage existing docker containers Check container logs Save and load profile Appendix Prerequisites to run Robustar Launcher Frequently asked questions 1. Overview of Robustar Launcher Robustar Launcher is shown below. It has three major functional partitions. Partition 1 contains 5 interactive buttons respectively used to save or load the pro\ufb01le of the server(i.e. the docker container of Robustar), and start, stop or delete the server. Partition 2 is a tab widget containing two tab pages, \u2019Create\u2019 tab page and \u2019Manage\u2019 tab page: Create tab page is for inputting information necessary for the creation of a new Robustar docker container. Manage page if for monitoring the existing containers of Robustar. Partition 3 is for displaying all the output of the launcher. Depending on the simplicity, the output is displayed di\ufb00erently in the three tab pages: Prompt tab page is for the simplest prompt given by the launcher program, telling users about whether an operation is carried out successfully. Details tab page is for outputting more detailed information yielded during an operation, which will not be displayed in the \u2019Prompt\u2019 tab page. Logs tab page is the most detailed, allowing users to check all logs redirected from the container. 2. Start Robustar Launcher To run Robustar Launcher. You can either run the executable file or the code to use it. But first you must ensure that few prerequisites are satis\ufb01ed. See here for more information. For running: If you are using the executable file, just double click it and run. If you are using the code, open a terminal under the directory launcher/ in the project source code and run the command python app.py When you start Robustar Launcher successfully, its initial interface appears as shown below containing all the functions required to interact with docker containers of Robustar. 3. Use Robustar Launcher Here is an outline of the various functions of Robustar Launcher: Create new docker container of Robustar Check existing docker containers of Robustar Manage existing docker containers of Robustar Check container logs Save and load profile Detailed instructions of these functions will be provided in turn below. 3.a. Create new docker container The process can be summarized into the following steps: Fill in all information in the Create tab page (some have default values). Click the Start Server button. Check the output in the Prompt tab page to see if the operation is carried out successfully. During the process, you can check the download progress in the Details tab page. The operation might not \ufb01nished immediately so it could take some time for you to see the output, especially when it is your \ufb01rst time using the selected docker image. Weight File can only be selected under the directory of Checkpoint . Once you have set the Checkpoint directory, all available weight files under it will be automatically listed in Weight File combo box, from which you can select one to initialize your model. 3.b. Check existing docker containers You can check all existing containers of Robustar in Manage tab page categorized by their states as shown below. There are three states of containers which we concern: Running containers are currently working. Exited containers have exited from running state. Created containers were created, but never had chance to run (most likely due to port con\ufb02ict). Since the lists update in response to user interaction, when a change happen in the background, they will not be aware of it. On such occasion, you can press the Refresh button on the bottom right corner of the tab page to enforce an update of the lists. 3.c. Manage existing docker containers There are three types of management operations, starting, stopping and deleting a server(i.e. a docker container of Robustar), corresponding to the three buttons Start Server , Stop Server and Delete Server on the left hand side. They share the same operation logic: Click to select a container from the lists in the Manage tab page. A container will be highlighted if selected. Click the corresponding button ( Start Server / Stop Server / Delete Server ). Check the output in the Prompt tab page to see if the operation is carried out successfully. The operation might not \ufb01nished immediately so it could take some time for you to see the output. We also support specifying container to be operated on with the container name inputted when you are in Create tab page. That means when you are in \u2019Create\u2019 tab page, you can also manage containers by clicking those buttons, and the container with the name you input in Docker Container Name will be operated. However, we suggest you to do so only under one condition, that is when you want to manage the container you just created. In other cases, it would be a better practice to manage the containers in Manage tab page. 3.d. Check container logs You can check the full logs of the running container in the Logs tab page as shown below. Currently the launcher only supports showing logs of the most recently started container after the launcher is started. In other words, if a container has been running before the launcher is started, or another container is started after it, then its logs will not be displayed. 3.e. Save and load pro\ufb01le You can save and load a profile(i.e. the setting in Create tab page) to save time from inputting duplicate information: To save a pro\ufb01le: Click the Save Pro\ufb01le button on the left hand side. Select a place in the pop-up window to save the pro\ufb01le as a .json \ufb01le. To load a pro\ufb01le: Click the Load Pro\ufb01le button on the left hand side. Select a .json \ufb01le containing the pro\ufb01le. 4. Appendix 4.a. Prerequisites to run Robustar Launcher To run Robustar Launcher, either the executable file or code, you must install and run the application Docker Desktop in your computer. If you are using Windows , please make sure the setting option in the red box as shown below is checked. If you are using the code to run Robustar Launcher, in addition to the above requirement, you must install Python packges Pyside2 and docker in your Python interpreter. 4.b. Frequently asked questions","title":"Launcher"},{"location":"tutorial/launcher/launcher/#introduction","text":"Robustar Launcher is an interactive app that you can use to control docker containers of Robustar. You can either run the executable file provided here or the code of it to use it.","title":"Introduction"},{"location":"tutorial/launcher/launcher/#contents","text":"Overview of Robustar Launcher Start Robustar Launcher Use Robustar Launcher Create new docker container Check existing docker containers Manage existing docker containers Check container logs Save and load profile Appendix Prerequisites to run Robustar Launcher Frequently asked questions","title":"Contents"},{"location":"tutorial/web/annotation/","text":"Annotation of Spurious Pixel Features Inspect data - Training data Navigation PREV PAGE - Go to the previous page GOTO PAGE - Go to a certain page NEXT PAGE - Go to the next page GOTO CLASS - Go to a certain class Display Enter the number of images per page Select the image size Annotate Hover on an image Click on the ANNOTATE button Adjust Size of the image Load Edit - load your previous annotation Auto Edit - directly filter out all the background pixels Use Free pencil to brush out the pixels that are considered spurious, adjust the brush size with Range Use Color Range to filter out all the background pixels with certain color range Auto Edit with Built-in segmentation mode Send Edit View edit results Allow annotators to calibrate the perception process of the vision models at a pixel level. The users can user canvas tool to annotate the spurious pixels of the images.","title":"Annotation"},{"location":"tutorial/web/annotation/#annotation-of-spurious-pixel-features","text":"Inspect data - Training data","title":"Annotation of Spurious Pixel Features"},{"location":"tutorial/web/annotation/#navigation","text":"PREV PAGE - Go to the previous page GOTO PAGE - Go to a certain page NEXT PAGE - Go to the next page GOTO CLASS - Go to a certain class","title":"Navigation"},{"location":"tutorial/web/annotation/#display","text":"Enter the number of images per page Select the image size","title":"Display"},{"location":"tutorial/web/annotation/#annotate","text":"Hover on an image Click on the ANNOTATE button Adjust Size of the image Load Edit - load your previous annotation Auto Edit - directly filter out all the background pixels Use Free pencil to brush out the pixels that are considered spurious, adjust the brush size with Range Use Color Range to filter out all the background pixels with certain color range Auto Edit with Built-in segmentation mode Send Edit View edit results Allow annotators to calibrate the perception process of the vision models at a pixel level. The users can user canvas tool to annotate the spurious pixels of the images.","title":"Annotate"},{"location":"tutorial/web/auto_annotation/","text":"Auto Annotation Enter the start index of samples Enter the end index of sample ( -1 means the end of all samples) Click START AUTO ANNOTATION You can annotate a certain set of images automatically.","title":"Auto Annotation"},{"location":"tutorial/web/auto_annotation/#auto-annotation","text":"Enter the start index of samples Enter the end index of sample ( -1 means the end of all samples) Click START AUTO ANNOTATION You can annotate a certain set of images automatically.","title":"Auto Annotation"},{"location":"tutorial/web/influence/","text":"Influence Input number of test samples Input r-averaging Start calculation You can use influence function to help identify the samples that need attention.","title":"Influence"},{"location":"tutorial/web/influence/#influence","text":"Input number of test samples Input r-averaging Start calculation You can use influence function to help identify the samples that need attention.","title":"Influence"},{"location":"tutorial/web/prediction/","text":"View model prediction Inspect Data - Annotated Data Hover on an image Click on the Predict button","title":"View model prediction"},{"location":"tutorial/web/prediction/#view-model-prediction","text":"Inspect Data - Annotated Data Hover on an image Click on the Predict button","title":"View model prediction"},{"location":"tutorial/web/task/","text":"Task center Train With annotation of spurious features all misleading samples, the users can directly use our system to update the model to improve its robustness against its tendency in learning the spurious features through our task center.","title":"Task Center"},{"location":"tutorial/web/task/#task-center","text":"Train With annotation of spurious features all misleading samples, the users can directly use our system to update the model to improve its robustness against its tendency in learning the spurious features through our task center.","title":"Task center"}]}